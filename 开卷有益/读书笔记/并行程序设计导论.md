# 《并行程序设计导论》读书笔记

## 第一章 为什么需要并行计算

随着摩尔定律(Moore's Law)的逐渐失效，微处理器的性能提升速度放缓，到2005年，大部分主流的微处理器制造商已经决定通过并行处理来快速提升微处理器的性能，他们不再继续开发速度更快的单处理器芯片，而是开始将多个完整的单处理器放到一个集成电路芯片上。

大多数串行程序是在单个处理器上运行的，不会因为简单地增加更多的处理器就获得极大的性能提升。因为串行程序不会意识到多个处理器的存在，它们在一个多处理器系统上运行的性能，往往与在多处理器系统的一个处理器上运行的性能相同。

### 1.1 为什么需要不断提升的性能

气候模拟、蛋白质折叠、药物发现、能源研究、数据分析等问题的解决都需要更加强大的算力。

### 1.2 为什么需要构建并行系统

日益增加的集成电路晶体管密度使得用空气冷却的集成电路的散热能力已经接近极限，同时制程的不断缩小使得晶体管之间的量子效应愈发明显，而这会影响计算的准确性，靠提升晶体管密度的方式来提升处理器的性能在物理上已经接近极限。因此并行系统的作用日益凸显。==在单个芯片上放置多个相对简单的处理器，这样的集成电路称为多核处理器==，**核**是中央处理器或CPU的代名词。

### 1.3 为什么要编写并行程序

大多数串行程序无法利用多核处理器，为了能够让程序更快地运行，就需要将串行程序改写为并行程序，这样才能充分利用多核。

### 1.4 怎样编写并行程序

编写并行程序有两种广泛采用的方法：

- 任务并行

  将多个任务分配到多个核上，每个核执行一个任务

- 数据并行

  多个核共同处理一个任务，但处理的是该任务中不同的数据部分。

### 1.5 将要学习的内容

- 共享内存系统

  - POSIX线程(POSIX threads, Pthreads)

  - OpenMP

- 分布式内存系统

  - 消息传递接口(Message-Passing Interface, MPI)

MPI和Pthreads是C语言的扩展库，可以在C程序中使用扩展的类型定义、函数和宏；而OpenMP包含了一个扩展库以及对C编译器的部分修改。

**Q：共享内存系统和分布式内存系统有什么区别？**

**A:**

在共享内存系统中，各个核能够共享访问计算机的内存，理论上每个和能够读、写内存的所有区域。因此可以通过检测和更新共享内存中的数据来协调各个核。

在分布式内存系统中，每个核都拥有自己的私有内存。核之间的通信是显式的，必须使用类似于在网络中发送消息的机制来传递数据。

**Q: 为什么共享内存系统有OpenMP和Pthreads两种扩展？**

**A:**OpenMP是对C语言相对更高层次的扩展，容易将很多程序并行化。

Pthreads和OpenMp有相似之处，但它也提供了一些在OpenMp中不可用的协调构造，增强了并行化其他一些程序的能力。

### 1.6 并行，并发和分布式

- 并行（parallel)

  在多个处理器上同时完成多个（可能相关的）任务

  ![img](https://raw.githubusercontent.com/chen-ustc/clouding/master/20190815220659208.png)

- 并发（concurrent）

  并发是在同一个处理器上同时做多件事，并发并不是真正意义上的并行，它只是用很快的速度在多个任务之间进行切换，使得宏观上看这些任务是同时执行的，但微观上，它还是串行的。

  ![并发处理](https://raw.githubusercontent.com/chen-ustc/clouding/master/20190815220124415.png)

- 分布式（distribute）

  在同一个网络里的多台机器上同时完成多个任务。

  

![img](https://raw.githubusercontent.com/chen-ustc/clouding/master/20190815220733376.png)

并行是紧耦合的，多核之间在物理上紧密靠近，通过共享内存或者高速网络相互连接。

分布式是松耦合的，任务是在多个计算机上执行，这些计算机相隔较远并且任务是由独立创建的程序来完成的。如网络搜索程序就是分布式的。